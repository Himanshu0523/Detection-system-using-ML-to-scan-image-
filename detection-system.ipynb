{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3324348,"sourceType":"datasetVersion","datasetId":576013,"isSourceIdPinned":false}],"dockerImageVersionId":31259,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Tools","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n\n# Deeplearning tools\nfrom tensorflow.keras import layers, models \nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D , MaxPool2D\nfrom keras.layers import Activation, Dropout , BatchNormalization , Flatten , Dense\nfrom keras.optimizers import Adam\nfrom keras.utils import to_categorical\n\n# Machine Learning Tools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"execution_failed":"2026-02-11T02:55:03.570Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nfrom tqdm import tqdm\n\n# Image paths\nimagePaths = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    #Only process files inside the 'images' folder\n    if 'images' in dirname:\n        for filename in filenames:\n            if filename.endswith('.png'):\n                imagePaths.append(os.path.join(dirname , filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T02:54:41.880016Z","iopub.execute_input":"2026-02-11T02:54:41.880448Z","iopub.status.idle":"2026-02-11T02:54:42.304058Z","shell.execute_reply.started":"2026-02-11T02:54:41.880410Z","shell.execute_reply":"2026-02-11T02:54:42.303072Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import tqdm\nimport os\nimport cv2\n\nData = []\nTarget = []\nresize = 150\n\ncat = {'Viral Pneumonia':'Pneumonia' , 'Normal':'Normal' , 'COVID':'Covid-19'}\n\nfor imagePath in tqdm.tqdm(imagePaths):\n    label = imagePath.split(os.path.sep)[-3]\n    #Extract the label from the parent folder (2 levels up to )\n\n    if label not in cat:\n        continue\n    image = cv2.imread(imagePath)\n    image = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image ,(resize , resize))/255.0  #Normalize image to [0 , 1]\n    Data.append(image)\n    Target.append(cat[label])\n\nprint(f\"Processed  {len(Data)} images with corresponding labels.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T02:53:30.875468Z","iopub.execute_input":"2026-02-11T02:53:30.875889Z","iopub.status.idle":"2026-02-11T02:54:23.032184Z","shell.execute_reply.started":"2026-02-11T02:53:30.875860Z","shell.execute_reply":"2026-02-11T02:54:23.031102Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 21165/21165 [00:52<00:00, 405.94it/s]  ","output_type":"stream"},{"name":"stdout","text":"Processed  15153 images with corresponding labels.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":16},{"cell_type":"raw","source":"print(len(Data))\nprint(len(Target))\n\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Label Encoding and to one hot encoding\n# example\n[[0. ,1. ,0. ] , # 'Normal' -> [0, 1, 0]\n\n[0. , 0. , 1. ], #'Pneumonia' -> [0, 0, 1]\n\n[1. ,0. ,0. ]]# 'Covid-19' -> [1, 0, 0]","metadata":{}},{"cell_type":"code","source":"le = LabelEncoder()\nlabels = le.fit_transform(Target)\nlabels = to_categorical(labels)\n\nprint(le.classes_)\nprint(labels[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T02:54:42.319747Z","iopub.execute_input":"2026-02-11T02:54:42.320098Z","iopub.status.idle":"2026-02-11T02:54:42.336312Z","shell.execute_reply.started":"2026-02-11T02:54:42.320060Z","shell.execute_reply":"2026-02-11T02:54:42.335423Z"}},"outputs":[{"name":"stdout","text":"['Covid-19' 'Normal' 'Pneumonia']\n[0. 1. 0.]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# Splitting Datase","metadata":{}},{"cell_type":"code","source":"X_train , x_test , y_train , y_test = train_test_split(Data, labels, test_size=0.2 , stratify=labels, random_state = 42)\n\n# Further split the training data into training and validation sets\n(x_train , x_val , y_train , y_val) = train_test_split(X_train, y_train, test_size=0.20, stratify=y_train , random_state=42)\n\ntrainX = np.array(x_train)\nvalX = np.array(x_val)\ntestX = np.array(x_test)\ntrainY = np.array(x_train)\nvalY = np.array(y_val)\ntestY = np.array(y_test)\n\nprint(\"Training data shape:\", trainX.shape)\nprint(\"Validation data shape: \", valX.shape)\nprint('Testing data shape: ', testX.shape)\nprint(\"Traing labels shape: \", trainY.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T02:54:48.042373Z","iopub.execute_input":"2026-02-11T02:54:48.042833Z","iopub.status.idle":"2026-02-11T02:54:53.109649Z","shell.execute_reply.started":"2026-02-11T02:54:48.042791Z","shell.execute_reply":"2026-02-11T02:54:53.108452Z"}},"outputs":[{"name":"stdout","text":"Training data shape: (9697, 150, 150, 3)\nValidation data shape:  (2425, 150, 150, 3)\nTesting data shape:  (3031, 150, 150, 3)\nTraing labels shape:  (9697, 150, 150, 3)\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"# CNN Modal Training","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T02:55:28.731574Z","iopub.execute_input":"2026-02-11T02:55:28.731878Z","iopub.status.idle":"2026-02-11T02:55:41.281893Z","shell.execute_reply.started":"2026-02-11T02:55:28.731853Z","shell.execute_reply":"2026-02-11T02:55:41.280828Z"}},"outputs":[{"name":"stderr","text":"2026-02-11 02:55:30.875142: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770778531.135260     120 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770778531.200858     120 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770778531.759996     120 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770778531.760048     120 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770778531.760051     120 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770778531.760054     120 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"s = 150\n\nmodel= Sequential()\n\n# we have two parts in cnn\n# feature learning\n\nmodel.add(Input(shape=(s, s, 3))) \nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3) , activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(1,1)))\nmodel.add(Dropout(0.25))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T02:55:41.283574Z","iopub.execute_input":"2026-02-11T02:55:41.285097Z","iopub.status.idle":"2026-02-11T02:55:41.298187Z","shell.execute_reply.started":"2026-02-11T02:55:41.285017Z","shell.execute_reply":"2026-02-11T02:55:41.296759Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_120/415844434.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# we have two parts in cnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"],"ename":"NameError","evalue":"name 'Sequential' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"\n# ann = dense layers\n\n# Nueral networks (Dense Layers)\nmodel.add(Flatten())\nmodel.add(Dense(64 , activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(3, activation=\"softmax\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T02:54:53.504542Z","iopub.execute_input":"2026-02-11T02:54:53.504912Z","iopub.status.idle":"2026-02-11T02:54:53.564066Z","shell.execute_reply.started":"2026-02-11T02:54:53.504871Z","shell.execute_reply":"2026-02-11T02:54:53.563274Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"\n# Compile the model\nmodel.compile(optimizer=keras.optimizers.Adam(),\n              loss=keras.losses.categorical_crossentropy,\n              metrics= ['accuracy'])\n\n# Train the model with validation data\nepochs = 25\nhistory = model.fit(trainX , trainY, epochs=epochs, batch_size=40, verbose=1, validation_data=(valX ,valY))","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-11T02:55:03.569Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Extract accuracy and loss deom the History Object","metadata":{}},{"cell_type":"code","source":"history.history","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-11T02:55:03.570Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training & validation accuracy values\nplt.figure(figsize=(12,5))\n\nplt.plot(1 , 2, 1)\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train' , 'Validation'])\n\n# plot training & validation loss value\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'])\nplt.plot(history,history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train' , 'Validation'])\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-11T02:55:03.570Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plotting Confusion Matrix","metadata":{}},{"cell_type":"code","source":"y_pred = model.perdict(testX)\ny_pred","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-11T00:11:18.581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = np.argmax(predictions , axis=1)\n\n# Convert testY from one-hot encoded to class labels (integers)\ny_true = np.argmax(testY , axis=1)\n\n# Convert confusion matrix\ncm = confusion_matrix(y_true , y_pred)\n\nprint(cm)","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-11T00:11:18.581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = le.classes","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-11T00:11:18.581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create DataFrames for the confusion matrix\nConfusion_Matrix = pd.DataFrame(cm , index=class_names , columns=class_names)\n\n# Plot the confusion matrix using seaborn's matrix\nplt.figure(figsize=(8, 7))\nsns.heatmap(Confusion_Matrix , annot=True, fmt='d' , cmap='Blues', cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Condusion Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-11T00:11:18.581Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\n\n# Classification report on test\n","metadata":{}},{"cell_type":"code","source":"# predIdxs = np.argmax(predIdxs , axis=1)\nprint(classification_report(y_true, y_pred , target_names=le.classes_, digits=5))","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-11T00:11:18.581Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save Model and Label Encoder","metadata":{}},{"cell_type":"code","source":"model.save('CNN_covid19_Xray_Version.h5') \n\nimport pickle\npickle.dump(le , open(\"Label encoder.pk1\" ,  'rb'))\nprint('saved')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load for inference","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the saved model\nmodel = load_model('CNN_Convid19_Xray_Version.h5')\n\nle = pickle.load(open(\"Label_encoder.pk1\" , \"rb\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" # Real Time Detection System","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef detection_system(image_path , model , label_encoder , image_size=150):\n    \"\"\"\n    Detection system function to classify an input image.\n\n    Parameters:\n    - image_path : the path to the image to classify\n    - model : the trained Keras model.\n    - label_encoder: the LabelEncoder used to encode the labels.\n    - image_size: the target size for resizing the image (default: 150*150)\n\n    Returns: \n    - predixted_label: the predicted class label.\n    - confidence_Score = confidence score - predicted class\n    \"\"\"\n    \n    # load images\n    image = cv2.imread(image_path)\n    \n    if image in None:\n        raise ValueError(f\"Image not found on this path, {image_path}\")\n    \n    # Preprocessing\n    image_rgb = cv2.cvColor(image , cv2.COLOR_BGR2RGB)\n    \n    image_resized = cv2.resize(image_rgb , {image_size , image_size})\n    \n    image_normalized = image_resized/ 255.0\n    \n    image_input = np.expand_dims(image_normalized ,axis=0)\n    \n    predictions = model.predict(image_input)\n    \n    predicted_index = np.argmax(predictions)\n    confidence_score = predictions[0][predicted_index]\n    \n    label = label_encoder.inverse_tranform([predicted_index])[0]\n\nreturn predixted_label , confidence_score\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example usage\nimage_path = '/kaggle/input/covid19-radiography-database/COVID19_Radiography_Dataset/Normal/images/'\npredicted_label , confidence_score = detection_system(image_path , model, le)\nprint(f\"Predicted Label: {Predicted_label} , Confidence_score: {Confidence_score * 100 : 2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n","metadata":{}}]}